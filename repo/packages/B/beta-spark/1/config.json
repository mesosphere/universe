{
  "type": "object",
  "properties": {
    "service": {
      "description": "DC/OS Spark configuration properties",
      "type": "object",
      "properties": {
        "name": {
          "default": "spark",
          "description": "The Spark Dispatcher will register with Mesos with this as a framework name.  This service will be available at http://<dcos_url>/service/<name>/",
          "type": "string"
        },
        "cpus": {
          "default": 1,
          "description": "CPU shares",
          "minimum": 0.0,
          "type": "number"
        },
        "mem": {
          "default": 1024.0,
          "description": "Memory (MB)",
          "minimum": 1024.0,
          "type": "number"
        },
        "role": {
          "description": "The Spark Dispatcher will register with Mesos with this role.",
          "type": "string",
          "default": "*"
        },
        "service_account": {
          "description": "The Spark Dispatcher will register with Mesos with this principal.",
          "type": "string",
          "default": ""
        },
        "service_account_secret": {
          "description": "The Spark Dispatcher will register with mesos with this secret.",
          "type": "string",
          "default": ""
        },
        "user": {
          "description": "Executors will run as this user.",
          "type": "string",
          "default": "root"
        },
        "docker-image": {
          "type": "string",
          "description": "The docker image used to run the dispatcher, drivers, and executors.  If, for example, you need a Spark built with a specific Hadoop version, set this variable to one of the images here: https://hub.docker.com/r/mesosphere/spark/tags/",
          "default": "mesosphere/spark:2.3.0-2.2.0-2-beta-hadoop-2.6"
        },
        "log-level": {
          "type": "string",
          "description": "log4j log level for The Spark Dispatcher.  May be set to any valid log4j log level: https://logging.apache.org/log4j/1.2/apidocs/org/apache/log4j/Level.html",
          "default": "INFO"
        },
        "spark-history-server-url": {
          "type": "string",
          "description": "URL of The Spark History Server (e.g. http://<dcos_url>/service/spark-history"
        },
        "UCR_containerizer": {
          "type": "boolean",
          "description": "Launch the Dispatcher using the Universal Container Runtime (UCR)",
          "default": false
        },
        "use_bootstrap_for_IP_detect": {
          "type": "boolean",
          "description": "Use the bootstrap utility for detecting host IP as opposed to using Spark's internal mechanism, see troubleshooting.md.",
          "default": false
        }
      }
    },
    "security": {
      "description": "Spark security configuration properties",
      "type": "object",
      "properties": {
        "kerberos": {
          "description": "Spark Kerberos configuration.",
          "type": "object",
          "properties": {
            "enabled": {
              "description": "Enable kerberos authentication.",
              "type": "boolean",
              "default": false
            },
            "kdc": {
              "description": "KDC settings for Kerberos",
              "type": "object",
              "properties": {
                "hostname": {
                  "type": "string",
                  "description": "The name or address of a host running a KDC for the realm."
                },
                "port": {
                  "type": "integer",
                  "description": "The port of the host running a KDC for that realm."
                }
              }
            },
            "realm": {
              "type": "string",
              "description": "The Kerberos realm used to render the principal."
            },
            "krb5conf": {
              "description": "Base64 encoded krb5.conf file.  Copied to the drivers and executors so that they may access your KDC. Providing this will override above settings.",
              "type": "string",
              "media": {
                "binaryEncoding": "base64",
                "type": "application/x-yaml"
              },
              "default": ""
            }
          }
        }
      }
    },
    "hdfs": {
      "description": "Spark-HDFS configuration properties",
      "type": "object",
      "properties": {
        "config-url": {
          "type": "string",
          "description": "Base URL that serves HDFS config files (hdfs-site.xml, core-site.xml).  If not set, DC/OS Spark will use its default configuration and read from DC/OS HDFS."
        }
      }
    }
  }
}
