{
  "type": "object",
  "properties": {
    "service": {
      "type": "object",
      "description": "DC/OS service configuration properties",
      "properties": {
        "name": {
          "description": "The name of the service instance",
          "type": "string",
          "default": "portworx-hadoop"
        },
        "virtual_network_enabled": {
          "description": "Enable virtual networking",
          "type": "boolean",
          "default": false
        },
        "virtual_network_name": {
          "description": "The name of the virtual network to join",
          "type": "string",
          "default": "dcos"
        },
        "virtual_network_plugin_labels": {
          "description": "Labels to pass to the virtual network plugin. Comma-separated key:value pairs. For example: k_0:v_0,k_1:v_1,...,k_n:v_n",
          "type": "string",
          "default": ""
        },
        "user": {
          "type": "string",
          "description": "The linux user used to run the scheduler and all executors.",
          "default": "root"
        },
        "service_account": {
          "description": "The service account for DC/OS service authentication. This is typically left empty to use the default unless service authentication is needed. The value given here is passed as the principal of Mesos framework.",
          "type": "string",
          "default": ""
        },
        "mesos_api_version": {
          "description": "Configures the Mesos API version to use. Possible values: V0 (non-HTTP), V1 (HTTP)",
          "type": "string",
          "default": "V0"
        },
        "service_account_secret": {
          "description": "Name of the Secret Store credentials to use for DC/OS service authentication. This should be left empty unless service authentication is needed.",
          "type": "string",
          "default": ""
        },
        "deploy_strategy": {
          "description": "HDFS deployment strategy. [parallel, serial]",
          "type": "string",
          "default": "parallel",
          "enum": [
            "parallel",
            "serial"
          ]
        },
        "update_strategy": {
          "description": "HDFS update strategy. [parallel, serial]",
          "type": "string",
          "default": "serial",
          "enum": [
            "parallel",
            "serial"
          ]
        },
        "log_level": {
          "description": "The log level for the DC/OS service.",
          "type": "string",
          "enum": [
            "OFF",
            "FATAL",
            "ERROR",
            "WARN",
            "INFO",
            "DEBUG",
            "TRACE",
            "ALL"
          ],
          "default": "INFO"
        },
        "tls": {
          "type": "object",
          "description": "TLS configuration properties.",
          "properties": {
            "enabled": {
              "description": "Enable TLS support (requires Strict mode).",
              "type": "boolean",
              "default": false
            }
          }
        },
        "kerberos": {
          "type": "object",
          "description": "Kerberos configuration properties.",
          "properties": {
            "enabled": {
              "description": "Enable kerberos authentication.",
              "type": "boolean",
              "default": false
            },
            "keytabs_uri": {
              "type": "string",
              "description": "The URI from which Keytabs tar.gz can be downloaded. Only relevant when secure_mode is enabled.",
              "default": ""
            },
            "krb5_conf_uri": {
              "type": "string",
              "description": "The URI of the krb5.conf file.  This file will be downloaded and used by each HDFS task."
            },
            "primary": {
              "type": "string",
              "description": "The Kerberos primary used by HDFS tasks.  The full principal will be <service.kerberos.primary>/<mesos_dns_address>@<service.kerberos.realm>",
              "default": "hdfs"
            },
            "primary_http": {
              "type": "string",
              "description": "The Kerberos primary used by the HTTP server running on HDFS tasks.  See <service.kerberos.primary>.",
              "default": "HTTP"
            },
            "realm": {
              "type": "string",
              "description": "The Kerberos realm used to render the principal of HDFS tasks.",
              "default": "LOCAL"
            }
          }
        }
      }
    },
    "journal_node": {
      "description": "HDFS configuration properties.",
      "type": "object",
      "properties": {
        "cpus": {
          "description": "Journal node CPU requirement",
          "type": "number",
          "default": 0.3
        },
        "mem": {
          "description": "Journal node memory requirement",
          "type": "number",
          "default": 2048
        },
        "disk": {
          "description": "Journal node disk size requirement in MB",
          "type": "number",
          "default": 5000
        },
        "portworx_volume_name": {
          "description": "Portworx volume name",
          "type": "string",
          "default": "HDFSJournalVolume"
        },
        "portworx_volume_options": {
          "description": "Portworx volume options. Comma separated key=value pairs",
          "type": "string",
          "default": ""
        },
        "enable_readiness_check": {
          "description": "Determines whether to enable readiness checks for Journal Nodes.",
          "type": "boolean",
          "default": true
        },
        "lagging_tx_count": {
          "description": "The number of transactions that this JournalNode is lagging",
          "type": "integer",
          "default": 0
        }
      },
      "required": [
        "cpus",
        "mem",
        "disk",
        "portworx_volume_name"
      ]
    },
    "name_node": {
      "description": "HDFS configuration properties.",
      "type": "object",
      "properties": {
        "cpus": {
          "description": "Name node CPU requirement",
          "type": "number",
          "default": 0.3
        },
        "mem": {
          "description": "Name node memory requirement",
          "type": "number",
          "default": 2048
        },
        "disk": {
          "description": "Name node disk size requirement in MB",
          "type": "number",
          "default": 5000
        },
        "portworx_volume_name": {
          "description": "Portworx volume name",
          "type": "string",
          "default": "HDFSNameVolume"
        },
        "portworx_volume_options": {
          "description": "Portworx volume options. Comma separated key=value pairs",
          "type": "string",
          "default": ""
        }
      },
      "required": [
        "cpus",
        "mem",
        "disk",
        "portworx_volume_name"
      ]
    },
    "zkfc_node": {
      "description": "HDFS configuration properties.",
      "type": "object",
      "properties": {
        "cpus": {
          "description": "ZKFC node CPU requirement",
          "type": "number",
          "default": 0.3
        },
        "mem": {
          "description": "ZKFC node memory requirement",
          "type": "number",
          "default": 2048
        }
      },
      "required": [
        "cpus",
        "mem"
      ]
    },
    "data_node": {
      "description": "HDFS configuration properties.",
      "type": "object",
      "properties": {
        "count": {
          "description": "Data node count requirement",
          "type": "number",
          "default": 3
        },
        "cpus": {
          "description": "Data node CPU requirement",
          "type": "number",
          "default": 0.3
        },
        "mem": {
          "description": "Data node memory requirement",
          "type": "number",
          "default": 2048
        },
        "disk": {
          "description": "Data node disk size requirement in MB",
          "type": "number",
          "default": 5000
        },
        "portworx_volume_name": {
          "description": "Portworx volume name",
          "type": "string",
          "default": "HDFSDataVolume"
        },
        "portworx_volume_options": {
          "description": "Portworx volume options. Comma separated key=value pairs",
          "type": "string",
          "default": ""
        }
      },
      "required": [
        "cpus",
        "mem",
        "disk",
        "portworx_volume_name"
      ]
    },
    "yarn_node": {
      "description": "Yarn configuration properties.",
      "type": "object",
      "properties": {
        "cpus": {
          "description": "Yarn node CPU requirement",
          "type": "number",
          "default": 2
        },
        "mem": {
          "description": "Yarn node memory requirement",
          "type": "number",
          "default": 2048
        },
        "scheduler_min_allocation_mb": {
          "description": "Minimum limit of memory to allocate to each container request at the Resource Manager.",
          "type": "number",
          "default": 128
        },
        "scheduler_max_allocation_mb": {
          "description": "Maximum limit of memory to allocate to each container request at the Resource Manager.",
          "type": "number",
          "default": 2048
        },
        "scheduler_min_allocation_vcores": {
          "description": "The minimum allocation for every container request at the RM, in terms of virtual CPU cores.",
          "type": "number",
          "default": 1
        },
        "scheduler_max_allocation_vcores": {
          "description": "The maximum allocation for every container request at the RM, in terms of virtual CPU cores",
          "type": "number",
          "default": 2
        },
        "nodemanager_memory_mb": {
          "description": "Physical memory, in MB, to be made available to running containers.",
          "type": "number",
          "default": 4096
        },
        "nodemanager_cpu_vcores": {
          "description": "Number of CPU cores that can be allocated for containers.",
          "type": "number",
          "default": 4
        }
      },
      "required": [
        "cpus",
        "mem",
        "scheduler_min_allocation_mb",
        "scheduler_max_allocation_mb",
        "scheduler_min_allocation_vcores",
        "scheduler_max_allocation_vcores",
        "nodemanager_memory_mb",
        "nodemanager_cpu_vcores"
      ]
    },
    "hdfs": {
      "type": "object",
      "description": "HDFS File System configuration options",
      "properties": {
        "administrators": {
          "type": "string",
          "description": "Administrators for the HDFS cluster",
          "default": "core,centos,azureuser"
        },
        "name_node_rpc_port": {
          "type": "integer",
          "description": "The RPC port for HDFS Name Nodes.",
          "default": 10001
        },
        "name_node_http_port": {
          "type": "integer",
          "description": "The HTTP port for HDFS Name Nodes. ",
          "default": 10002
        },
        "zkfc_port": {
          "type": "integer",
          "description": "The port for ZKFC Nodes. ",
          "default": 8019
        },
        "journal_node_rpc_port": {
          "type": "integer",
          "description": "The RPC port used by Journal Nodes.",
          "default": 8485
        },
        "journal_node_http_port": {
          "type": "integer",
          "description": "The HTTP port used by Journal Nodes.",
          "default": 8480
        },
        "data_node_rpc_port": {
          "type": "integer",
          "description": "The RPC port used by Data Nodes.",
          "default": 10003
        },
        "data_node_http_port": {
          "type": "integer",
          "description": "The HTTP port used by Data Nodes.",
          "default": 10004
        },
        "data_node_ipc_port": {
          "type": "integer",
          "description": "The IPS port used by Data Nodes.",
          "default": 10005
        },
        "permissions_enabled": {
          "type": "boolean",
          "description": "If true, permissions checking is enabled",
          "default": false
        },
        "name_node_heartbeat_recheck_interval": {
          "type": "integer",
          "description": "This time decides the interval to check for expired datanodes.",
          "default": 60000
        },
        "compress_image": {
          "type": "boolean",
          "description": "If true, the File System image will be compressed.",
          "default": true
        },
        "image_compression_codec": {
          "type": "string",
          "description": "The image compression codec for the File System image.",
          "default": "org.apache.hadoop.io.compress.SnappyCodec"
        },
        "hadoop_root_logger": {
          "type": "string",
          "description": "",
          "default": "INFO,console"
        },
        "ipc_client_connect_max_retries": {
          "type": "integer",
          "description": "Indicates the number of retries a client will make to establish a server connection.",
          "default": 300
        }
      },
      "required": [
        "name_node_rpc_port",
        "name_node_http_port",
        "journal_node_rpc_port",
        "journal_node_http_port",
        "data_node_rpc_port",
        "data_node_http_port",
        "data_node_ipc_port",
        "permissions_enabled",
        "name_node_heartbeat_recheck_interval",
        "compress_image",
        "image_compression_codec"
      ]
    }
  }
}
